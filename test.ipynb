{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models to: /Users/arjun/.ggml-models\n",
      "Downloading ggml-tiny.bin...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "whisper_init_from_file_no_state: loading model from '/Users/arjun/.ggml-models/ggml-tiny.bin'\n",
      "whisper_model_load: loading model\n",
      "whisper_model_load: n_vocab       = 51865\n",
      "whisper_model_load: n_audio_ctx   = 1500\n",
      "whisper_model_load: n_audio_state = 384\n",
      "whisper_model_load: n_audio_head  = 6\n",
      "whisper_model_load: n_audio_layer = 4\n",
      "whisper_model_load: n_text_ctx    = 448\n",
      "whisper_model_load: n_text_state  = 384\n",
      "whisper_model_load: n_text_head   = 6\n",
      "whisper_model_load: n_text_layer  = 4\n",
      "whisper_model_load: n_mels        = 80\n",
      "whisper_model_load: f16           = 1\n",
      "whisper_model_load: type          = 1\n",
      "whisper_model_load: mem required  =  129.00 MB (+    3.00 MB per decoder)\n",
      "whisper_model_load: adding 1608 extra tokens\n",
      "whisper_model_load: model ctx     =   73.58 MB\n",
      "whisper_model_load: model size    =   73.54 MB\n",
      "whisper_init_state: kv self size  =    2.62 MB\n",
      "whisper_init_state: kv cross size =    8.79 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data..\n",
      "Transcribing..\n",
      "[00:00:00.000 --> 00:00:11.000]   And so my fellow Americans ask not what your country can do for you ask what you can do for your country.\n",
      "Extracting text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "whisper_full_with_state: progress =   5%\n",
      "whisper_full_with_state: progress =  10%\n",
      "whisper_full_with_state: progress =  15%\n",
      "whisper_full_with_state: progress =  20%\n",
      "whisper_full_with_state: progress =  25%\n",
      "whisper_full_with_state: progress =  30%\n",
      "whisper_full_with_state: progress =  35%\n",
      "whisper_full_with_state: progress =  40%\n",
      "whisper_full_with_state: progress =  45%\n",
      "whisper_full_with_state: progress =  50%\n",
      "whisper_full_with_state: progress =  55%\n",
      "whisper_full_with_state: progress =  60%\n",
      "whisper_full_with_state: progress =  65%\n",
      "whisper_full_with_state: progress =  70%\n",
      "whisper_full_with_state: progress =  75%\n",
      "whisper_full_with_state: progress =  80%\n",
      "whisper_full_with_state: progress =  85%\n",
      "whisper_full_with_state: progress =  90%\n",
      "whisper_full_with_state: progress =  95%\n",
      "whisper_full_with_state: progress = 100%\n"
     ]
    }
   ],
   "source": [
    "from whispercpp import Whisper\n",
    "\n",
    "w = Whisper('tiny')\n",
    "\n",
    "result = w.transcribe(\"jfk.wav\")\n",
    "text = w.extract_text(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cython_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
